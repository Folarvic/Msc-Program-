{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINANCIAL ECONOMETRICS\n",
    "\n",
    "MODULE 4 | LESSON 4\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ARIMA MODEL**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                     |                                                                                                                             |\n",
    "| :------------------ | :-------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Reading Time**    | 60 minutes                                                                                                                  |\n",
    "| **Prior Knowledge** | Basics of time series, Moving average, Autoregressive                                                                       |\n",
    "| **Keywords**        | ARMA model, ARIMA model, Causality, Invertibility, The principle of parsimony, AIC, BIC, Box-Jenkins Method, Ljung-Box Test |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_In previous lessons, we learned about the basics of time series, moving average models, and autoregressive models. In this lesson, we are going to use all the time series knowledge we have learned and apply it to this lesson. We are going to introduce the ARIMA model. The ARIMA model combines the AR model and MA model as one model for time series analysis. The Box-Jenkins method provides all the modeling steps for the ARIMA model so the Box-Jenkins method and ARIMA model can be used interchangeably. We will talk about what the ARIMA model is and how to apply it to analyze a time series. Before talking about the ARIMA model, let's start with the ARMA model._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (16, 9)  # Figure size and width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Microsoft VS Code\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Finncial Econometrics/M2/M4/M4. dxy_r_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Download the dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m m4_data = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFinncial Econometrics/M2/M4/M4. dxy_r_data.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m dxyr_data = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33mM4. dxy_r_data.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Convert date variable to date format\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'Finncial Econometrics/M2/M4/M4. dxy_r_data.csv'"
     ]
    }
   ],
   "source": [
    "# Download the dataset\n",
    "m4_data = pd.read_csv(\"Finncial Econometrics/M2/M4/M4. dxy_r_data.csv\")\n",
    "dxyr_data = pd.read_csv(\"M4. dxy_r_data.csv\")\n",
    "\n",
    "# Convert date variable to date format\n",
    "m4_data[\"Date2\"] = pd.to_datetime(m4_data[\"Date\"], format=\"%m/%d/%Y\")\n",
    "dxyr_data[\"Date2\"] = pd.to_datetime(dxyr_data[\"Date\"], format=\"%m/%d/%Y\")\n",
    "\n",
    "# Selecting columns and setting index\n",
    "goog = m4_data.loc[:, [\"Date2\", \"GOOGLE\"]].set_index(\"Date2\")\n",
    "ust10 = m4_data.loc[:, [\"Date2\", \"UST10Y\"]].set_index(\"Date2\")\n",
    "dxy = dxyr_data[[\"Date2\", \"DXY_R\"]].set_index(\"Date2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. ARMA Model**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARMA stands for **autoregressive moving average model**. An ARMA model combines an autoregressive model (AR model) and a moving average model (MA model) to model stationary time series.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.1 Definition of ARMA($p,q$) Model**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define an ARMA($p,q$) model as follows:\n",
    "\n",
    "A time series ${X_{t}}$ is ARMA($p,q$) if it is stationary and\n",
    "\n",
    "$$ X*{t} = \\alpha*{1} X*{t-1} + \\cdots + \\alpha*{p} X*{t-p} + W*{t} + \\theta*{1} W*{t-1} + \\cdots + \\theta*{q} W*{t-q} $$\n",
    "\n",
    "Where $\\alpha_{p} \\neq 0, \\theta_{q} \\neq 0$ and $W$ is a normal white noise with mean = $0$ and variance = $\\sigma^{2}$. The parameters $p$ and $q$ are called the autoregressive order and moving average order.\n",
    "\n",
    "We can see from the above model, if $q = 0$, then ARMA($p, 0$) is an AR($p$) model. If $p = 0$, then ARMA($0, q$) is an MA($q$) model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.2 Properties of ARMA($p,q$)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARMA($p$, $q$) can also be written as follows:\n",
    "\n",
    "$$ \\alpha(B) X*{t} = \\theta(B) W*{t} $$\n",
    "\n",
    "Where:\n",
    "\n",
    "> $\\alpha(B)$ is AR polynomial and is equal to $\\alpha(B) = 1 - \\alpha_{1}B - \\alpha_{2} B^{2} - \\cdots - \\alpha_{p} B^{p}$\n",
    ">\n",
    "> $\\theta(B)$ is MA polynomial and is equal to $\\theta(B) = 1 + \\theta_{1} B + \\theta_{2} B^{2} + \\cdots + \\theta_{p} B^{q}$\n",
    "\n",
    "With the above AR and MA polynomials, we can do the following calculations:\n",
    "\n",
    "> a. Set the two polynomials to $0$ and solve for $B$. <br>\n",
    "> b. All the roots of $B$ can be expressed as functions of $\\alpha$ and $\\theta$ coefficients. <br>\n",
    "> c. Set the absolute values of all the roots of $B >1$, then convert all the inequalities in terms of $\\alpha$ and $\\theta$ coefficients. Now we have a set of inequalities to regulate $\\alpha$ and $\\theta$ coefficients <br>\n",
    "> d. With these regularity conditions on $\\alpha$ and $\\theta$ coefficients, we can ensure that an ARMA($p,q$) time series $X_{t}$ can only be expressed as a function of its past values and not its future values. This property is called **causality**. The regularity conditions also ensure that $\\{W_{t}\\}$ from ARMA($p,q$) can be expressed as an infinite AR process. This property is called **invertibility**. <br>\n",
    "\n",
    "Sometimes, we can find several models that work for our dataset. With several model options, we can choose the simplest one with the fewest parameters. Let's look at one ARMA example. Assume we have an ARMA(2,2) process as follows:\n",
    "\n",
    "$$ X*{t} = 0.2 X*{t-1} + 0.35 X*{t-2} + W*{t} + W*{t-1} + 0.25 W*{t-2} $$\n",
    "\n",
    "We can rewrite the above ARMA(2,2) as follows:\n",
    "\n",
    "$$ (1 - 0.2B - 0.35B^{2}) X*{t} = (1 + B + 0.25B^{2}) W*{t} $$\n",
    "\n",
    "Then, we can rewrite them in various factors:\n",
    "\n",
    "$$ (1 - 0.7B) (1 + 0.5B) X*{t} = (1 - 0.5B) (1 + 0.5B) W*{t} $$\n",
    "\n",
    "Then, the model can be simplified as follows:\n",
    "\n",
    "$$ (1 - 0.7B) X*{t} = (1 - 0.5B) W*{t} $$\n",
    "\n",
    "an ARMA(1,1) model instead of an ARMA(2,2).\n",
    "\n",
    "The above rule of selecting the model with the least number of coefficients or the simplest model is called **the principle of parsimony**.\n",
    "<span style='color: transparent; font-size:1%'>All rights reserved WQU WorldQuant University QQQQ</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. ARIMA Model**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARIMA Model stands for autoregressive integrated moving average model. Why do we add \"integrated\" into the name of the ARIMA model? \"Integrated\" in the ARIMA model means to include the differencing method to remove trend or seasonality in a time series. We learned from the last section that an ARMA model only handles stationary time series. It is different for an ARIMA model. An ARIMA model can handle non-stationary time series.\n",
    "\n",
    "Let's go over ARIMA's definition:\n",
    "\n",
    "A time series $X_{t}$ follows a ARIMA($p,d,q$) process if $\\nabla^{d} X_{t} = (1-B)^{d} X_{t}$ is ARMA($p,q$).\n",
    "\n",
    "In general, we can write the ARIMA($p,d,q$) as follows:\n",
    "\n",
    "$$ \\nabla^{d} X*{t} = \\alpha*{1} \\nabla^{d} X*{t-1} + \\alpha*{2} \\nabla^{d} X*{t-2} + \\cdots + \\alpha*{p} \\nabla^{d} X*{t-p} + \\theta*{1} W*{t-1} + \\theta*{2} W*{t-2} + \\cdots + \\theta*{q} W*{t-q} + W*{t} $$\n",
    "\n",
    "We can also rewrite the model as follows:\n",
    "\n",
    "$$ \\alpha(B) (1-B)^{d} X*{t} = \\theta(B) W*{t} $$\n",
    "\n",
    "In ARIMA($p,d,q$), $p$ is the order of the AR component, $d$ is the order of differencing and $q$ is the order of the MA component.\n",
    "\n",
    "We have learned a few time series models so far, they can all be special cases of ARIMA model. Figure 1 summarizes these models in terms of ARIMA representation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 1: Special Cases for ARIMA Model**\n",
    "\n",
    "| Time Series Model        | ARIMA($p,d,q$) Representation |\n",
    "| :----------------------- | :---------------------------- |\n",
    "| White Noise              | ARIMA(0,0,0)                  |\n",
    "| Random Walk              | ARIMA(0,1,0) with no constant |\n",
    "| Random Walk with a Drift | ARIMA(0,1,0) with a constant  |\n",
    "| Autoregressive           | ARIMA($p$,0,0)                |\n",
    "| Moving Average           | ARIMA(0,0,$q$)                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Model Selection Criteria: AIC and BIC**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before going into Box-Jenkins method, we would like to go over some metrics used to select the best time series model among several choices.\n",
    "\n",
    "The first one is **Akaike's information criterion (AIC)**. This is a metric that measures the goodness of fit for a model and can balance the trade off between less precise predictions vs. number of parameters in the model. The lower the AIC, the better the model. AIC is preferred when the sample size is small.\n",
    "\n",
    "The second one is **Bayesian information criterion (BIC)**. It is also called Schwarz information criterion (SIC). BIC also measures the goodness of fit for a model by balancing the error of the model and the number of parameters. However, BIC puts more emphasis on penalizing number of parameters. Because of this feature in BIC, it usually prefers a simpler model with less parameters. We also look for a lowest BIC when comparing among several model candidates.\n",
    "\n",
    "In general, the AIC and BIC results would match. However, there are occasions where the two results would not be the same. If the results are different, one can report both. In the following examples, we will use AIC.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Box-Jenkins Methodology**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Box-Jenkins method was first introduced by George Box and Gwilym Jenkins. The Box-Jenkins method offers a methodology to derive models for time series data. The steps in Box-Jenkins method consist of\n",
    "\n",
    "> - model identification,\n",
    "> - model estimation, and\n",
    "> - model diagnostics.\n",
    "\n",
    "In the rest of the section, we will briefly discuss each step, and we will provide an application in the next section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.1 Model Identification**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use time series plot, ACF plot, and PACF plot and other information to select the order of AR($p$), order of differencing ($d$), or order of MA($q$) for a ARIMA model. Many times the plots or information at hand do not give us clear information to identify ($p,d,q$). For example, if both $p$ and $q$ are greater than $0$, both ACF and PACF plots will decline geometrically. In that case, we can create a list of possible ARIMA models with various $p,d,q$ combinations. We will then run each ARIMA model and record their AICs and BICs. Then, we choose the model with the smallest AIC and BIC values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2 Model Estimation**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Box-Jenkins method uses a maximum likelihood method and back-testing to estimate an ARIMA model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.3 Model Diagnostics**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the model is built, we will use a residual plot, a residual QQ plot, ACF of residuals, and the Ljung-Box test to check the goodness-of-fit of the model. We use a residual plot to see if there is any pattern that shows up. We are looking for a random pattern if the model is constructed accurately. For a residual QQ plot, we are looking for the normality of residuals. ACF of residuals will give us an idea if there is autocorrelation among error terms from the model. The Ljung-Box test is to check if there is any overall autocorrelation in the residuals. Then, we will show you how to conduct the forecast once the model is finalized.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. ARIMA Application: Google Stock Price**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we are going to demonstrate how to apply ARIMA to build a model for financial assets. We will use Google's stock price as an example. We will follow the Box-Jenkins methodology to build this model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.1 Model Identification and Model Estimation**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model identification has always been a trial-and-error process. We usually try different model candidates until we get a satisfactory one. During the process of searching for a fit model, we will of course estimate a model candidate. Hence, in this section, we will combine model identification and model estimation together.\n",
    "\n",
    "First, let's plot Google's stock time series plot, ACF plot, and PACF plot to take a look at the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 2: Time Series Plot, ACF Plot, and PACF Plot for Google Stock Price from 2016 to 2021**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series plot of Google stock price with ACF and PACF\n",
    "\n",
    "# Plot of Google stock price\n",
    "plt.plot(goog)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Google Stock Price\")\n",
    "plt.show()\n",
    "\n",
    "# plot ACF and PACF\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
    "sm.graphics.tsa.plot_acf(goog, title=\"Google stock ACF\", lags=50, ax=ax1)\n",
    "sm.graphics.tsa.plot_pacf(goog, title=\"Google stock PACF\", lags=50, ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the time series plot in figure 1 that there is an upward trend for Google stock price from 2016 to 2021. The ACF plot also shows a slow decreasing trend, which indicates a trend in the time series.\n",
    "\n",
    "By using the Box-Jenkins method, we will try to use the differencing method to remove the trend and keep investigating the time series.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 3: Plot of First Differencing of Google Stock Price**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of First Differencing of Google Stock Price\n",
    "plt.plot(goog.diff().dropna())\n",
    "plt.ylabel(\"First Difference of Google Stock\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From figure 3, we can see that now the differenced time series oscillates around $0$, but the recent movements are more volatile. This indicates that the variance is not constant. It is very common for the financial time series data to have non-constant variance. One way to adjust the time series with non-constant variance is to take the log of the time series. Let's take the log of Google's stock price and do the first differencing. The first difference of the logged Google stock price is very close to Google stock price return, if the return is relatively small. Therefore, in many finance research field, the above method is a way to get the return for a financial asset. Figure 4 shows the result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 4: Plot First Differencing of Log of Google Stock Price**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot First Differencing of Log of Google Stock Price\n",
    "plt.plot(np.log(goog).diff().dropna())\n",
    "plt.ylabel(\"First Difference of Log of Google Stock\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From figure 4, we can see the new time series has a more stable variance even though the second half of the investigated period still has higher variation. We will introduce another time series model to model non-constant variance in the next module. For now, let's check ACF and PACF plots for the first difference of logged Google stock price.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 5: ACF and PACF Plots for First Difference of Logged Google Stock Price**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACF and PACF Plots for First Difference of Logged Google Stock Price\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
    "sm.graphics.tsa.plot_acf(\n",
    "    np.log(goog).diff().dropna(),\n",
    "    title=\"First Difference of Logged Google stock ACF\",\n",
    "    lags=30,\n",
    "    ax=ax1,\n",
    ")\n",
    "sm.graphics.tsa.plot_pacf(\n",
    "    np.log(goog).diff().dropna(),\n",
    "    title=\"First Difference of Logged Google stock PACF\",\n",
    "    lags=30,\n",
    "    ax=ax2,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From figure 5, it seems that we can try $p=1$ and/or $q=1$ or any other combinations. Fortunately, the statistical software, can automatically test several models and report back the best model with the lowest AIC. The following report shows various ARIMA models and their corresponding AICs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 6: ARIMA Model Selection Report**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Efficient ARIMA model Selection\n",
    "mod_can_auto = auto_arima(\n",
    "    np.log(goog).dropna(),  # stepwise=False,\n",
    "    start_p=0,\n",
    "    start_d=0,\n",
    "    start_q=0,\n",
    "    max_p=3,\n",
    "    max_d=3,\n",
    "    max_q=3,\n",
    "    trace=True,\n",
    "    with_intercept=False,\n",
    "    return_valid_fits=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In figure 6, we can see the software ran a couple of ARIMA models and reported their AICs.\n",
    "\n",
    "On the left of the table is the ARIMA model specifications, and on the right is the model AICs. The best model from the software is ARIMA(1,1,0) with intercept. We can see that ARIMA(1,1,0) with intercept has the lowest AIC(-8112.960) among other model candidates. Figure 7 shows the MLE estimation for the ARIMA(1,1,0) model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 7: ARIMA(1,1,0) Model Estimation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best ARIMA Model for Google stock price\n",
    "mod_can_a = SARIMAX(\n",
    "    np.log(goog), order=(1, 1, 0), trend=\"c\"\n",
    ").fit()  # This is the best model in Python implementation\n",
    "print(mod_can_a.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.2 Model Diagnostics**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have identified the ARIMA model to model Google stock price and have built and estimated the model. Let's check our model diagnostics to see if there are some potential structural patterns in Google stock price time series that our ARIMA model does not capture.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 8: Diagnostic Report for ARIMA(1,1,0) Model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic Report for ARIMA(1,1,0) Model\n",
    "mod_can_a.plot_diagnostics()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ljung-Box test for no serial correlation of standardized residuals\n",
    "lb_test = mod_can_a.test_serial_correlation(\n",
    "    method=\"ljungbox\", df_adjust=True, lags=None\n",
    ")\n",
    "\n",
    "# plot Ljung-Box test p-values and 0.05 significance line\n",
    "plt.figure(figsize=(14, 2))\n",
    "plt.plot(lb_test[0][1], linestyle=\"\", marker=\"o\")\n",
    "plt.axhline(y=0.05, color=\"blue\", linestyle=\"--\")\n",
    "plt.title(\"p-values for Ljung-Box statistic\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In figure 8, we produce a number of graphs for model diagnostics. The first one is the standardized residuals graph. We can see from the residuals graph that there is a period where the variation is higher than other periods. In the next module, we will introduce a method to model non-constant variance for time series data. In the ACF plot for the residuals, the ACFs below lag 5 are not significant. However, lag 6 to lag 9 are still significant. There might be seasonality activity that the model does not capture. From the QQ plot for the residuals, we can see the residuals are not normally distributed since the plot shows fat tails on both ends. The last graph is the Ljung-Box test. What is the Ljung-Box test?\n",
    "\n",
    "The Ljung-Box test is to test if a group of autocorrelations from model residuals are small enough to claim the residuals are independent. The test conducts $n$ hypothesis tests for the following $n$ autocorrelation groups:\n",
    "\n",
    "> Group 1: autocorrelation 1 <br>\n",
    "> Group 2: autocorrelation 1, autocorrelation 2 <br>\n",
    "> Group 3: autocorrelation 1, autocorrelation 2, autocorrelation 3 <br> > $\\quad \\vdots$ <br>\n",
    "> Group $n$: autocorrelation 1, autocorrelation 2, autocorrelation 3, â€¦., autocorrelation $n$ <br>\n",
    "\n",
    "Each hypothesis test is constructed as follows:\n",
    "\n",
    "> - Null hypothesis $H_0$: all autocorrelations in the group are small enough so that residuals are independent\n",
    "> - Alternative hypothesis $H_1$: all autocorrelations in the group are not small enough so that the residuals are not independent\n",
    "\n",
    "If the $p$-value from each hypothesis test is $> 0.05$, we cannot reject the null hypothesis. We then conclude that residuals from this model are independent.\n",
    "\n",
    "Now that we know what the Ljung-Box test is, we can look at the test graph report in figure 8. From the plot, we see that the groups with lags equal to and less than 5 are all not significant. However, from lag 6 and afterwards, there are some autocorrelations that exist from Ljung-Box Test. Combining this piece of information with ACF plot for residuals, we see there might be a seasonality component that the model neglects to capture.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.3 Forecast of ARIMA(0,1,1)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, once we are satisfied with our model result, we will start to forecast where Google's stock price will be. In figure 9, we forecast Google stock prices for the next 100 days with 80% confidence interval and 95% confidence interval.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 9: Forecast Plot of ARIMA(1,1,0) with 80% Confidence Interval and 95% Confidence Interval**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast Plot of ARIMA(1,1,0) with 95% Confidence Interval\n",
    "\n",
    "# Plot Google data\n",
    "ffx = goog.copy()\n",
    "ffx.index = [i for i in range(len(ffx))]  # Set numeric index\n",
    "ffx.plot(ylabel=\"Google Stock Price\", title=\"Forecast from ARIMA(1,1,0)\", color=\"k\")\n",
    "\n",
    "# get forecast data for next 100 steps\n",
    "forecast = mod_can_a.get_forecast(steps=100)\n",
    "forecast_mean = np.exp(forecast.predicted_mean)  # mean of forecast data\n",
    "conf_int95 = forecast.conf_int(alpha=0.05)  # 95% confidence interval\n",
    "conf_int80 = forecast.conf_int(alpha=0.2)  # 80% confidence interval\n",
    "\n",
    "# plot mean forecast and 95% and 80% confidence intervals\n",
    "plt.plot(forecast_mean, c=\"b\")\n",
    "plt.fill_between(\n",
    "    conf_int95.index,\n",
    "    np.exp(conf_int95[\"lower GOOGLE\"]),\n",
    "    np.exp(conf_int95[\"upper GOOGLE\"]),\n",
    "    color=\"b\",\n",
    "    alpha=0.3,\n",
    ")\n",
    "plt.fill_between(\n",
    "    conf_int80.index,\n",
    "    np.exp(conf_int80[\"lower GOOGLE\"]),\n",
    "    np.exp(conf_int80[\"upper GOOGLE\"]),\n",
    "    color=\"b\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From figure 9, we can see that there is a 80% chance (darker blue shade) that Google's stock price will move within 2400 and 3600 for the next 100 days.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Shiny Application for ARIMA Models**\n",
    "\n",
    "In this module, we provide a Shiny application to build an ARIMA model for Google's stock price.\n",
    "\n",
    "[Click here to access the application.](https://worldquantuniversity.shinyapps.io/3FE-Module-4-Lesson-4/?_ga=2.114852039.1981594217.1661291782-1173458961.1656095235) The first tab gives you the opportunity to apply different transformation methods to Google's stock price. There are two transformation choices: difference and natural log. The application will show the time series graph for transformed variables as well as ACF and PACF graphs.\n",
    "\n",
    "In the ARIMA Model tab, you can build an ARIMA model for Google's stock price. The transformation method used in this model is natural log. You choose the parameters for the model and hit the run button to generate the model result. Not all parameter combinations will generate a model result, so you need to play with the parameter selections to build a model.\n",
    "\n",
    "Once the model is built, the next two tabs will give you the model diagnostic information and forecast graph.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. Conclusion**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we introduced the ARMA model and ARIMA model. We first went through the definitions and properties of ARMA and ARIMA models. We then introduced the Box-Jenkins method to build an ARIMA model. We used the example of Google's stock price to demonstrate the model identification, estimation, and model diagnostics steps to build an ARIMA model. We also showed the model's forecast result. This lesson concludes the introductory module on time series analysis. So far, we have assumed that variation in a time series is constant. However, in financial data, this is not always the case. In the next module, we will learn how to model time series with non-constant variance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **References**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Box, George, and Gwilym Jenkins. Time Series Analysis: Forecasting and Control. Holden-Day, 1970\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "Copyright 2025 WorldQuant University. This\n",
    "content is licensed solely for personal use. Redistribution or\n",
    "publication of this material is strictly prohibited.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNyQynE/mM2ELgvEoy9x3oJ",
   "name": "Lesson Notes - ECON_Module 4_Lesson 4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
